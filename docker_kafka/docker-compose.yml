version: '3.8'
networks:
  default:
    name: t-dat-901-network

services:
  # Zookeeper pour kafka
  zookeeper-server:
    container_name: t-dat-901-zookeeper
    image: wurstmeister/zookeeper
    hostname: 't-dat-901-zookeeper'
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default
    ports:
      - '2181:2181'
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_SERVER_ID=1

  kafka-server1:
    image: 'confluentinc/cp-kafka:latest'
    container_name: 'kafka-server1'
    hostname: 'kafka-server1'
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9092 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default 
    ports:
      - '9092:9092'
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper-server:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-server1:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      #- KAFKA_BROKER_ID=1
    depends_on:
      - zookeeper-server

  kafka-server2:
    image: 'confluentinc/cp-kafka:latest'
    container_name: 'kafka-server2'
    hostname: 'kafka-server2'
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9092 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default 
    ports:
      - '9093:9092'
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper-server:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-server2:9092
      - KAFKA_BROKER_ID=2
    depends_on:
      - zookeeper-server

  kafka-server3:
    image: 'confluentinc/cp-kafka:latest'
    container_name: 'kafka-server3'
    hostname: 'kafka-server3'
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9092 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default 
    ports:
      - '9094:9092'
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper-server:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-server3:9092
      - KAFKA_BROKER_ID=3
    depends_on:
      - zookeeper-server

  kafka-sr1:
    image: 'confluentinc/cp-schema-registry:latest'
    container_name: 'kafka-sr1'
    hostname: 'kafka-sr1'
    healthcheck:
      test: ["CMD-SHELL", "nc -z kafka-sr1 8081 || exit 1" ]
      interval: 5s
      timeout: 5s
      retries: 60
    networks:
      - default
    ports:
      - '8084:8081'
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=kafka-server1:9092,kafka-server2:9092,kafka-server3:9092
      - SCHEMA_REGISTRY_HOST_NAME=kafka-sr1
      - SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081
    depends_on:
      - zookeeper-server

  kafka-connect1:
    image: 'confluentinc/cp-kafka-connect:latest'
    container_name: 'kafka-connect1'
    hostname: 'kafka-connect1'
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 8082 || exit 1" ]
      interval: 5s
      timeout: 5s
      retries: 60
    networks:
      - default
    ports:
      - '8083:8082'
    volumes:
      - ./vol-kafka-connect-jar:/etc/kafka-connect/jars
      - ./vol-kafka-connect-conf:/etc/kafka-connect/connectors
    environment:
      - CONNECT_BOOTSTRAP_SERVERS=kafka-server1:9092,kafka-server2:9092,kafka-server3:9092
      - CONNECT_REST_PORT=8082
      - CONNECT_GROUP_ID=cassandraConnect
      - CONNECT_CONFIG_STORAGE_TOPIC=cassandraconnect-config
      - CONNECT_OFFSET_STORAGE_TOPIC=cassandraconnect-offset
      - CONNECT_STATUS_STORAGE_TOPIC=cassandraconnect-status
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false
      - CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false
      - CONNECT_REST_ADVERTISED_HOST_NAME=kafka-connect
      - CONNECT_PLUGIN_PATH=/etc/kafka-connect/jars
    depends_on:
      - zookeeper-server
      - kafka-server1
      - kafka-server2
      - kafka-server3
      - cassandra-microservice
      - vue-app-microservice

  # Redpanda pour avoir une interface graphique de gestion de kafka
  redpanda:
    container_name: t-dat-901-redpanda
    image: docker.redpanda.com/redpandadata/redpanda:latest
    command:
      - redpanda
      - start
      - --smp
      - '1'
      - --reserve-memory
      - 0M
      - --overprovisioned
      - --node-id
      - '0'
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:29092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda:29092
      - --pandaproxy-addr
      - PLAINTEXT://0.0.0.0:28082,OUTSIDE://0.0.0.0:8082
      - --advertise-pandaproxy-addr
      - PLAINTEXT://redpanda:28082,OUTSIDE://localhost:8082
    ports:
      - 29092:29092
      - 8082:8082
      - 8081:8081
      - 9644:9644
    networks:
      - default

  console:
    container_name: t-dat-901-console
    image: docker.redpanda.com/redpandadata/console:latest
    entrypoint: /bin/sh
    command: -c "sleep 60 && echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 8080 || exit 1" ]
      interval: 5s
      timeout: 5s
      retries: 60
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["host.docker.internal:9092"]
          schemaRegistry:
            enabled: true
            urls: ["http://host.docker.internal:8081"]
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://host.docker.internal:9644"]
        connect:
          enabled: true
          clusters:
            - name: tdat901
              url: http://host.docker.internal:8080
    ports:
      - 8080:8080
    depends_on:
      - redpanda
    networks:
      - default
  #  volumes:
  #     - ./config/redpanda-console-config.yaml:/etc/redpanda/redpanda-console-config.yaml Pas prend en compte config optionnel
  # Fin config redpanda

  # Grafana pour le monitoring
  grafana:
    image: grafana/grafana
    container_name: t-dat-901-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - grafana-conf:/etc/grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    depends_on:
      - kafka-server1
      - kafka-server2
      - kafka-server3
      - cassandra-microservice
    networks:
      - default

  # Récupérer les monitorings avec prometheus 
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    depends_on:
      - kafka-server1
      - kafka-server2
      - kafka-server3
      - cassandra-microservice
    networks:
      - default

  # Cassandra microservice
  cassandra-microservice:
    image: cassandra:latest
    mem_limit: 4g
    container_name: 'cassandra-microservice'
    hostname: 'cassandra-microservice'
    healthcheck:
      test: ["CMD-SHELL", "cqlsh", "-e", "describe keyspaces" ]
      interval: 30s
      timeout: 5s
      retries: 60
    networks:
      - default
    ports:
      - "9042:9042"
    volumes:
      - ./config/cassandra.yaml:/etc/cassandra/cassandra.yaml
      - ./cassandra:/var/lib/cassandra
      - ./scripts:/docker-entrypoint-initdb.d
  # Fin de config cassandra

  # Front-end vuejs de l'appilication
  vue-app-builder:
    image: node:latest
    container_name: vue-app-builder
    working_dir: /usr/src/app
    volumes:
      - /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/front/crypto_currency_t_dat_901:/usr/src/app
    command: /bin/sh -c "npm install && npm run build"

  vue-app-microservice:
    image: nginx:latest
    container_name: vue-app-microservice
    hostname: 'vue-app-microservice'
    ports:
      - '5173:80'
    volumes:
      - ./config/nginx-default.conf:/etc/nginx/conf.d/default.conf
      - /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/front/crypto_currency_t_dat_901/dist:/usr/src/app

  create-topic-for-vue:
    image: confluentinc/cp-kafka:latest
    container_name: create-topic-for-vue
    entrypoint: /bin/bash
    command: -c "sleep 10 && kafka-topics --create --topic front_cryptoviz --partitions 3 --replication-factor 1 --bootstrap-server kafka-server1:9092"
    depends_on:
      - zookeeper-server
      - kafka-server1
    networks:
      - default
    volumes:
      - ./init-scripts:/docker-entrypoint-initdb.d

  kafka-consumer-front:
    build:
      context: /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/front/crypto_currency_t_dat_901
      dockerfile: /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/docker_kafka/config/dockerfile-front
    container_name: kafka-consumer-front
    environment:
      - KAFKA_SERVERS=kafka-server1:9092
      - KAFKAJS_NO_PARTITIONER_WARNING=1
      - KAFKA_GROUP_ID=front-end-group
    depends_on:
      - zookeeper-server
      - kafka-server1
      - kafka-server2
      - kafka-server3
      - create-topic-for-vue 
    networks:
      - default
    command: /bin/sh -c "sleep 60 && node KafkaConsumer.js"

  kafka-producer-front:
    build:
      context: /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/front/crypto_currency_t_dat_901
      dockerfile: /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/docker_kafka/config/dockerfile-front
    container_name: kafka-producer-front
    environment:
      - KAFKA_SERVERS=kafka-server1:9092
    depends_on:
      - zookeeper-server
      - kafka-server1
      - kafka-server2
      - kafka-server3
      - create-topic-for-vue
    networks:
      - default
    command: /bin/sh -c "sleep 60 && node KafkaProducer.js"
  # Fin de la config front-end

  # Config du fichié python pour save dans la bdd
  python-crypto-task:
    build:
      context: ./config
      dockerfile: dockerfile-python
    container_name: python-crypto-task
    command: /bin/sh -c "sleep 90 && python3 /app/crypto.py"
    volumes:
      - ../back/api_crypto/api_server_python:/app
    ports:
      - "11002:11002"
    networks:
      - default

  # Lancement des serveurs Node.js
  server-api-crypto:
    build:
      context: .
      dockerfile: config/dockerfile-nodejs
    container_name: server-api-crypto
    command: sh -c "npm install express cors axios && sleep 60 && node /app/server.js"
    volumes:
      - /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/back/api_crypto:/app
    ports:
      - "11003:11003"
    networks:
      - default

  server-api-bdd-front:
    build:
      context: .
      dockerfile: config/dockerfile-nodejs
    container_name: server-api-bdd-front
    command: sh -c "npm install express cors cassandra-driver  && sleep 60 && node /app/bdd_front.js"
    volumes:
      - /Users/macpro-loic/Documents/epitech_msc_pro/T-DAT-901/projet/back/api_crypto:/app
    ports:
      - "11004:11004"
    networks:
      - default
  # Fin du lancement des serveurs Node.js

volumes:
  grafana-data:
  grafana-conf: